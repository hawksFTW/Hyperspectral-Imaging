{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"models.ipynb","provenance":[],"authorship_tag":"ABX9TyNBBdou+wza75uMBGM+gkt3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"y7hyH7mnMTtQ","executionInfo":{"status":"ok","timestamp":1643482574220,"user_tz":480,"elapsed":4973,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}}},"outputs":[],"source":["# import the necessary packages\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","source":["def create_mlp(dim, regress=False):\n","\t# define our MLP network\n","\tmodel = Sequential()\n","\tmodel.add(Dense(8, input_dim=dim, activation=\"relu\"))\n","\tmodel.add(Dense(4, activation=\"relu\"))\n","\n","\t# check to see if the regression node should be added\n","\tif regress:\n","\t\tmodel.add(Dense(1, activation=\"linear\"))\n","\n","\t# return our model\n","\treturn model\n","\n","def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n","\t# initialize the input shape and channel dimension, assuming\n","\t# TensorFlow/channels-last ordering\n","\tinputShape = (height, width, depth)\n","\tchanDim = -1\n","\n","\t# define the model input\n","\tinputs = Input(shape=inputShape)\n","\n","\t# loop over the number of filters\n","\tfor (i, f) in enumerate(filters):\n","\t\t# if this is the first CONV layer then set the input\n","\t\t# appropriately\n","\t\tif i == 0:\n","\t\t\tx = inputs\n","\n","\t\t# CONV => RELU => BN => POOL\n","\t\tx = Conv2D(f, (3, 3), padding=\"same\")(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = BatchNormalization(axis=chanDim)(x)\n","\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","\t# flatten the volume, then FC => RELU => BN => DROPOUT\n","\tx = Flatten()(x)\n","\tx = Dense(16)(x)\n","\tx = Activation(\"relu\")(x)\n","\tx = BatchNormalization(axis=chanDim)(x)\n","\tx = Dropout(0.5)(x)\n","\n","\t# apply another FC layer, this one to match the number of nodes\n","\t# coming out of the MLP\n","\tx = Dense(4)(x)\n","\tx = Activation(\"relu\")(x)\n","\n","\t# check to see if the regression node should be added\n","\tif regress:\n","\t\tx = Dense(1, activation=\"linear\")(x)\n","\n","\t# construct the CNN\n","\tmodel = Model(inputs, x)\n","\n","\t# return the CNN\n","\treturn model"],"metadata":{"id":"89L4UWr9Mi5E","executionInfo":{"status":"ok","timestamp":1643482594730,"user_tz":480,"elapsed":445,"user":{"displayName":"hawksFTW","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10550048566476126053"}}},"execution_count":2,"outputs":[]}]}